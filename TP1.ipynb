{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81494bf",
   "metadata": {},
   "source": [
    "# Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a48a2828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48038010",
   "metadata": {},
   "source": [
    "# Importation et affichage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d978d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"sample.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f36019",
   "metadata": {},
   "source": [
    "# Nettoyage des données :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70c677",
   "metadata": {},
   "source": [
    "# Mise en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34fc7bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  @applesupport causing the reply to be disregar...  \n",
      "1  @105835 your business means a lot to us. pleas...  \n",
      "2  @76328 i really hope you all change but i'm su...  \n",
      "3  @105836 livechat is online at the moment - htt...  \n",
      "4  @virgintrains see attached error message. i've...  \n"
     ]
    }
   ],
   "source": [
    "df = df[['tweet_id', 'text']]\n",
    "def clean_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "df['text_cleaned'] = df['text'].apply(clean_text)\n",
    "print(df[['tweet_id', 'text', 'text_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648db3d",
   "metadata": {},
   "source": [
    "# Suppression des ponctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ce335a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  AppleSupport causing the reply to be disregard...  \n",
      "1  105835 Your business means a lot to us Please ...  \n",
      "2  76328 I really hope you all change but Im sure...  \n",
      "3  105836 LiveChat is online at the moment  https...  \n",
      "4  VirginTrains see attached error message Ive tr...  \n"
     ]
    }
   ],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "\n",
    "df['text_cleaned'] = df['text'].apply(remove_punctuation)\n",
    "print(df[['tweet_id', 'text', 'text_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ae8f7",
   "metadata": {},
   "source": [
    "# Suppression des mots vides (stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5d4ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  @AppleSupport causing reply disregarded tapped...  \n",
      "1  @105835 business means lot us. Please DM name,...  \n",
      "2      @76328 really hope change I'm sure won't! to!  \n",
      "3  @105836 LiveChat online moment - https://t.co/...  \n",
      "4  @VirginTrains see attached error message. I've...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\d\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "texts = df['text']\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "df['text_cleaned'] = texts.apply(remove_stopwords)\n",
    "print(df[['tweet_id', 'text', 'text_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59636e9a",
   "metadata": {},
   "source": [
    "# Suppression des mots fréquents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e6cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  @AppleSupport causing reply be disregarded tap...  \n",
      "1  @105835 Your business means lot us. Please DM ...  \n",
      "2  @76328 really hope all change but I'm sure won...  \n",
      "3  @105836 LiveChat online at moment - https://t....  \n",
      "4  @VirginTrains see attached error message. I've...  \n"
     ]
    }
   ],
   "source": [
    "word_freq = pd.Series(' '.join(texts).split()).value_counts()\n",
    "threshold = 10\n",
    "most_common_words = word_freq[:threshold].index\n",
    "\n",
    "def remove_common_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in most_common_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['text_cleaned'] = texts.apply(remove_common_words)\n",
    "print(df[['tweet_id', 'text', 'text_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0202f",
   "metadata": {},
   "source": [
    "# Suppression des mots rares :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6b00ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  @AppleSupport the reply to be and the under th...  \n",
      "1  means a lot to us. Please DM your name, code a...  \n",
      "2                I hope you all but I'm you you have  \n",
      "3  @105836 is at the moment - or 031 031 option 3...  \n",
      "4  @VirginTrains see I've tried a several times i...  \n"
     ]
    }
   ],
   "source": [
    "word_freq = pd.Series(' '.join(texts).split()).value_counts()\n",
    "threshold = 1\n",
    "rare_words = word_freq[word_freq <= threshold].index\n",
    "\n",
    "def remove_rare_words(text):\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in rare_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "df['text_cleaned'] = texts.apply(remove_rare_words)\n",
    "print(df[['tweet_id', 'text', 'text_cleaned']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7432d6",
   "metadata": {},
   "source": [
    "# Stemming :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85292db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\d\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_stemmed  \n",
      "0  @ applesupport caus the repli to be disregard ...  \n",
      "1  @ 105835 your busi mean a lot to us . pleas dm...  \n",
      "2  @ 76328 i realli hope you all chang but i 'm s...  \n",
      "3  @ 105836 livechat is onlin at the moment - htt...  \n",
      "4  @ virgintrain see attach error messag . i 've ...  \n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "df['text_stemmed'] = texts.apply(stem_text)\n",
    "print(df[['tweet_id', 'text', 'text_stemmed']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c481c540",
   "metadata": {},
   "source": [
    "# Lemmatisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ca7d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\d\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                     text_lemmatized  \n",
      "0  @ AppleSupport causing the reply to be disrega...  \n",
      "1  @ 105835 Your business mean a lot to u . Pleas...  \n",
      "2  @ 76328 I really hope you all change but I 'm ...  \n",
      "3  @ 105836 LiveChat is online at the moment - ht...  \n",
      "4  @ VirginTrains see attached error message . I ...  \n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "df['text_lemmatized'] = texts.apply(lemmatize_text)\n",
    "print(df[['tweet_id', 'text', 'text_lemmatized']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50de3e9a",
   "metadata": {},
   "source": [
    "# Suppression des émojis , Suppression des émoticônes, Suppression des URL, Suppression des balises HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ecad11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id                                               text  \\\n",
      "0    119237  @AppleSupport causing the reply to be disregar...   \n",
      "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
      "2    119239  @76328 I really hope you all change but I'm su...   \n",
      "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
      "4    119241  @VirginTrains see attached error message. I've...   \n",
      "\n",
      "                                        text_cleaned  \n",
      "0  @AppleSupport causing the reply to be disregar...  \n",
      "1  @105835 Your business means a lot to us. Pleas...  \n",
      "2  @76328 I really hope you all change but I'm su...  \n",
      "3  @105836 LiveChat is online at the moment -  or...  \n",
      "4  @VirginTrains see attached error message. I've...  \n"
     ]
    }
   ],
   "source": [
    "def remove_special_characters(text):\n",
    "    \n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[\\U00010000-\\U0010ffff]+', '', text)\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    return text\n",
    "\n",
    "df['text_cleaned'] = texts.apply(remove_special_characters)\n",
    "print(df[['tweet_id', 'text', 'text_cleaned']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75ab9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
